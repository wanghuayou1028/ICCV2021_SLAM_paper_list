# ICCV2021_SLAM_Autonomous_driving_paper_list
ICCV2021 paper list about Autonomous driving, SLAM, VO, Localization, Feature, SFM, Place recognition, Optical flow, Point cloud registration, Depth estimation, Robust estimation, etc.

#### Autonomous driving:

1. [Structured Bird's-Eye-View Traffic Scene Understanding From Onboard Images](https://openaccess.thecvf.com/content/ICCV2021/html/Can_Structured_Birds-Eye-View_Traffic_Scene_Understanding_From_Onboard_Images_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Can_Structured_Birds-Eye-View_Traffic_Scene_Understanding_From_Onboard_Images_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Can_Structured_Birds-Eye-View_Traffic_ICCV_2021_supplemental.pdf)] 
2. Chen_MultiSiam_Self-Supervised_Multi-Instance_Siamese_Representation_Learning_for_Autonomous_Driving_ICCV_2021_paper [[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_MultiSiam_Self-Supervised_Multi-Instance_Siamese_Representation_Learning_for_Autonomous_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Chen_MultiSiam_Self-Supervised_Multi-Instance_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.12178)] 
3. Chitta_NEAT_Neural_Attention_Fields_for_End-to-End_Autonomous_Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Chitta_NEAT_Neural_Attention_Fields_for_End-to-End_Autonomous_Driving_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2109.04456)]
4. Cui_LookOut_Diverse_Multi-Future_Prediction_and_Planning_for_Self-Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Cui_LookOut_Diverse_Multi-Future_Prediction_and_Planning_for_Self-Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Cui_LookOut_Diverse_Multi-Future_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2101.06547)]
5. Das_TMCOSS_Thresholded_Multi-Criteria_Online_Subset_Selection_for_Data-Efficient_Autonomous_Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Das_TMCOSS_Thresholded_Multi-Criteria_Online_Subset_Selection_for_Data-Efficient_Autonomous_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Das_TMCOSS_Thresholded_Multi-Criteria_ICCV_2021_supplemental.pdf)]
6. Ettinger_Large_Scale_Interactive_Motion_Forecasting_for_Autonomous_Driving_The_Waymo_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ettinger_Large_Scale_Interactive_Motion_Forecasting_for_Autonomous_Driving_The_Waymo_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ettinger_Large_Scale_Interactive_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2104.10133)]
7. Luo_Exploring_Simple_3D_Multi-Object_Tracking_for_Autonomous_Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Luo_Exploring_Simple_3D_Multi-Object_Tracking_for_Autonomous_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Luo_Exploring_Simple_3D_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.10312)]
8. Ren_Safety-Aware_Motion_Prediction_With_Unseen_Vehicles_for_Autonomous_Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ren_Safety-Aware_Motion_Prediction_With_Unseen_Vehicles_for_Autonomous_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ren_Safety-Aware_Motion_Prediction_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.01510)] 
9. Schon_MGNet_Monocular_Geometric_Scene_Understanding_for_Autonomous_Driving_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Schon_MGNet_Monocular_Geometric_Scene_Understanding_for_Autonomous_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Schon_MGNet_Monocular_Geometric_ICCV_2021_supplemental.zip)]
10. Zhang_X-World_Accessibility_Vision_and_Autonomy_Meet_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_X-World_Accessibility_Vision_and_Autonomy_Meet_ICCV_2021_paper.pdf)]
11. [ACDC: The Adverse Conditions Dataset With Correspondences for Semantic Driving Scene Understanding](https://openaccess.thecvf.com/content/ICCV2021/html/Sakaridis_ACDC_The_Adverse_Conditions_Dataset_With_Correspondences_for_Semantic_Driving_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Sakaridis_ACDC_The_Adverse_Conditions_Dataset_With_Correspondences_for_Semantic_Driving_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Sakaridis_ACDC_The_Adverse_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.13395)]

#### SLAM:

1. Dusmanu_Cross-Descriptor_Visual_Localization_and_Mapping_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Dusmanu_Cross-Descriptor_Visual_Localization_and_Mapping_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Dusmanu_Cross-Descriptor_Visual_Localization_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2012.01377)]
2. Larsson_Orthographic-Perspective_Epipolar_Geometry_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Larsson_Orthographic-Perspective_Epipolar_Geometry_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Larsson_Orthographic-Perspective_Epipolar_Geometry_ICCV_2021_supplemental.pdf)] 
3. Sucar_iMAP_Implicit_Mapping_and_Positioning_in_Real-Time_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Sucar_iMAP_Implicit_Mapping_and_Positioning_in_Real-Time_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Sucar_iMAP_Implicit_Mapping_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2103.12352)]
4. Zhu_Transfusion_A_Novel_SLAM_Method_Focused_on_Transparent_Objects_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Transfusion_A_Novel_SLAM_Method_Focused_on_Transparent_Objects_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhu_Transfusion_A_Novel_ICCV_2021_supplemental.pdf)]

#### VO:

1. Liu_MBA-VO_Motion_Blur_Aware_Visual_Odometry_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_MBA-VO_Motion_Blur_Aware_Visual_Odometry_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Liu_MBA-VO_Motion_Blur_ICCV_2021_supplemental.pdf)]
2. [The Surprising Effectiveness of Visual Odometry Techniques for Embodied PointGoal Navigation](https://openaccess.thecvf.com/content/ICCV2021/html/Zhao_The_Surprising_Effectiveness_of_Visual_Odometry_Techniques_for_Embodied_PointGoal_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_The_Surprising_Effectiveness_of_Visual_Odometry_Techniques_for_Embodied_PointGoal_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhao_The_Surprising_Effectiveness_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.11550)]

#### Feature & matching:

1. Berton_Viewpoint_Invariant_Dense_Matching_for_Visual_Geolocalization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Berton_Viewpoint_Invariant_Dense_Matching_for_Visual_Geolocalization_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Berton_Viewpoint_Invariant_Dense_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.09827)]
2. Chen_Learning_To_Match_Features_With_Seeded_Graph_Matching_Network_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Learning_To_Match_Features_With_Seeded_Graph_Matching_Network_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Chen_Learning_To_Match_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08771)]
3. Hong_Deep_Matching_Prior_Test-Time_Optimization_for_Dense_Correspondence_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Hong_Deep_Matching_Prior_Test-Time_Optimization_for_Dense_Correspondence_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Hong_Deep_Matching_Prior_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2106.03090)]
4. Truong_Warp_Consistency_for_Unsupervised_Learning_of_Dense_Correspondences_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Truong_Warp_Consistency_for_Unsupervised_Learning_of_Dense_Correspondences_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Truong_Warp_Consistency_for_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.03308)]
5. Wang_P2-Net_Joint_Description_and_Detection_of_Local_Features_for_Pixel_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_P2-Net_Joint_Description_and_Detection_of_Local_Features_for_Pixel_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wang_P2-Net_Joint_Description_ICCV_2021_supplemental.pdf)]
6. Zhang_ELSD_Efficient_Line_Segment_Detector_and_Descriptor_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_ELSD_Efficient_Line_Segment_Detector_and_Descriptor_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_ELSD_Efficient_Line_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.14205)]
7. Zhang_Self-Supervised_Pretraining_of_3D_Features_on_Any_Point-Cloud_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Self-Supervised_Pretraining_of_3D_Features_on_Any_Point-Cloud_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_Self-Supervised_Pretraining_of_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2101.02691)]
8. Zhao_Multi-Scale_Matching_Networks_for_Semantic_Correspondence_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Multi-Scale_Matching_Networks_for_Semantic_Correspondence_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhao_Multi-Scale_Matching_Networks_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.00211)] 

#### Back-end:

1. Demmel_Square_Root_Marginalization_for_Sliding-Window_Bundle_Adjustment_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Demmel_Square_Root_Marginalization_for_Sliding-Window_Bundle_Adjustment_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Demmel_Square_Root_Marginalization_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.02182)]
2. Li_PoGO-Net_Pose_Graph_Optimization_With_Graph_Neural_Networks_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_PoGO-Net_Pose_Graph_Optimization_With_Graph_Neural_Networks_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Li_PoGO-Net_Pose_Graph_ICCV_2021_supplemental.pdf)]
3. Lin_BARF_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lin_BARF_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lin_BARF_Bundle-Adjusting_Neural_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.06405)]
4. Tanaka_Learning_To_Bundle-Adjust_A_Graph_Network_Approach_to_Faster_Optimization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Tanaka_Learning_To_Bundle-Adjust_A_Graph_Network_Approach_to_Faster_Optimization_ICCV_2021_paper.pdf)] 

#### Localization:

1. Brachmann_On_the_Limits_of_Pseudo_Ground_Truth_in_Visual_Camera_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Brachmann_On_the_Limits_of_Pseudo_Ground_Truth_in_Visual_Camera_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Brachmann_On_the_Limits_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.00524)] 
2. Hyeon_Pose_Correction_for_Highly_Accurate_Visual_Localization_in_Large-Scale_Indoor_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Hyeon_Pose_Correction_for_Highly_Accurate_Visual_Localization_in_Large-Scale_Indoor_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Hyeon_Pose_Correction_for_ICCV_2021_supplemental.pdf)]
3. Kim_PICCOLO_Point_Cloud-Centric_Omnidirectional_Localization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_PICCOLO_Point_Cloud-Centric_Omnidirectional_Localization_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kim_PICCOLO_Point_Cloud-Centric_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.06545)] 
4. Wang_Continual_Learning_for_Image-Based_Camera_Localization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Continual_Learning_for_Image-Based_Camera_Localization_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wang_Continual_Learning_for_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.09112)]

#### SFM:

1. **Lindenberger_Pixel-Perfect_Structure-From-Motion_With_Featuremetric_Refinement_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lindenberger_Pixel-Perfect_Structure-From-Motion_With_Featuremetric_Refinement_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lindenberger_Pixel-Perfect_Structure-From-Motion_With_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08291)] （最佳学生论文）**
2. Iglesias_Radial_Distortion_Invariant_Factorization_for_Structure_From_Motion_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Iglesias_Radial_Distortion_Invariant_Factorization_for_Structure_From_Motion_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Iglesias_Radial_Distortion_Invariant_ICCV_2021_supplemental.zip)] 
3. Moran_Deep_Permutation_Equivariant_Structure_From_Motion_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Moran_Deep_Permutation_Equivariant_Structure_From_Motion_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Moran_Deep_Permutation_Equivariant_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.06703)]
4. Shabani_Extreme_Structure_From_Motion_for_Indoor_Panoramas_Without_Visual_Overlaps_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Shabani_Extreme_Structure_From_Motion_for_Indoor_Panoramas_Without_Visual_Overlaps_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Shabani_Extreme_Structure_From_ICCV_2021_supplemental.pdf)]
5. Zeng_PR-RRN_Pairwise-Regularized_Residual-Recursive_Networks_for_Non-Rigid_Structure-From-Motion_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zeng_PR-RRN_Pairwise-Regularized_Residual-Recursive_Networks_for_Non-Rigid_Structure-From-Motion_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zeng_PR-RRN_Pairwise-Regularized_Residual-Recursive_ICCV_2021_supplemental.zip)]

#### Optical flow:

1. Li_GyroFlow_Gyroscope-Guided_Unsupervised_Optical_Flow_Learning_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_GyroFlow_Gyroscope-Guided_Unsupervised_Optical_Flow_Learning_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2103.13725)]
2. Poggi_Sensor-Guided_Optical_Flow_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Poggi_Sensor-Guided_Optical_Flow_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Poggi_Sensor-Guided_Optical_Flow_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.15321)] 
3. Zhang_Separable_Flow_Learning_Motion_Cost_Volumes_for_Optical_Flow_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Separable_Flow_Learning_Motion_Cost_Volumes_for_Optical_Flow_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_Separable_Flow_Learning_ICCV_2021_supplemental.pdf)]
4. [High-Resolution Optical Flow From 1D Attention and Correlation](https://openaccess.thecvf.com/content/ICCV2021/html/Xu_High-Resolution_Optical_Flow_From_1D_Attention_and_Correlation_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_High-Resolution_Optical_Flow_From_1D_Attention_and_Correlation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_High-Resolution_Optical_Flow_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2104.13918)] 

#### Robust estimator:

1. Aiger_Efficient_Large_Scale_Inlier_Voting_for_Geometric_Vision_Problems_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Aiger_Efficient_Large_Scale_Inlier_Voting_for_Geometric_Vision_Problems_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2107.11810)]
2. Ivashechkin_VSAC_Efficient_and_Accurate_Estimator_for_H_and_F_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ivashechkin_VSAC_Efficient_and_Accurate_Estimator_for_H_and_F_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ivashechkin_VSAC_Efficient_and_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2106.10240)]

#### Place recognition:

1. Hui_Pyramid_Point_Cloud_Transformer_for_Large-Scale_Place_Recognition_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Hui_Pyramid_Point_Cloud_Transformer_for_Large-Scale_Place_Recognition_ICCV_2021_paper.pdf)]
2. Peng_Attentional_Pyramid_Pooling_of_Salient_Visual_Residuals_for_Place_Recognition_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Peng_Attentional_Pyramid_Pooling_of_Salient_Visual_Residuals_for_Place_Recognition_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Peng_Attentional_Pyramid_Pooling_ICCV_2021_supplemental.pdf)]
3. Peng_Conformer_Local_Features_Coupling_Global_Representations_for_Visual_Recognition_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Peng_Conformer_Local_Features_Coupling_Global_Representations_for_Visual_Recognition_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Peng_Conformer_Local_Features_ICCV_2021_supplemental.pdf)] 

#### Point cloud completion:

1. Huang_RFNet_Recurrent_Forward_Network_for_Dense_Point_Cloud_Completion_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_RFNet_Recurrent_Forward_Network_for_Dense_Point_Cloud_Completion_ICCV_2021_paper.pdf)]
2. Luo_PU-EVA_An_Edge-Vector_Based_Approximation_Solution_for_Flexible-Scale_Point_Cloud_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Luo_PU-EVA_An_Edge-Vector_Based_Approximation_Solution_for_Flexible-Scale_Point_Cloud_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Luo_PU-EVA_An_Edge-Vector_ICCV_2021_supplemental.pdf)]
3. Xiang_SnowflakeNet_Point_Cloud_Completion_by_Snowflake_Point_Deconvolution_With_Skip-Transformer_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xiang_SnowflakeNet_Point_Cloud_Completion_by_Snowflake_Point_Deconvolution_With_Skip-Transformer_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xiang_SnowflakeNet_Point_Cloud_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.04444)] 
4. [PoinTr: Diverse Point Cloud Completion With Geometry-Aware Transformers](https://openaccess.thecvf.com/content/ICCV2021/html/Yu_PoinTr_Diverse_Point_Cloud_Completion_With_Geometry-Aware_Transformers_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_PoinTr_Diverse_Point_Cloud_Completion_With_Geometry-Aware_Transformers_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Yu_PoinTr_Diverse_Point_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08839)]

#### Point cloud registration:

1. Lee_Deep_Hough_Voting_for_Robust_Global_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_Deep_Hough_Voting_for_Robust_Global_Registration_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2109.04310)]
2. Cao_PCAM_Product_of_Cross Attention_Matrices_for_Rigid_Registration_of_Point_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Cao_PCAM_Product_of_Cross-Attention_Matrices_for_Rigid_Registration_of_Point_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Cao_PCAM_Product_of_ICCV_2021_supplemental.pdf)]
3. Deng_A_Robust_Loss_for_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Deng_A_Robust_Loss_for_Point_Cloud_Registration_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Deng_A_Robust_Loss_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.11682)]
4. Jiang_Sampling_Network_Guided_Cross-Entropy_Method_for_Unsupervised_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Sampling_Network_Guided_Cross-Entropy_Method_for_Unsupervised_Point_Cloud_Registration_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2109.06619)]
5. Jubran_Provably_Approximated_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jubran_Provably_Approximated_Point_Cloud_Registration_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jubran_Provably_Approximated_Point_ICCV_2021_supplemental.pdf)] 
6. Lee_DeepPRO_Deep_Partial_Point_Cloud_Registration_of_Objects_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_DeepPRO_Deep_Partial_Point_Cloud_Registration_of_Objects_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lee_DeepPRO_Deep_Partial_ICCV_2021_supplemental.pdf)] 
7. Liu_LSG-CPD_Coherent_Point_Drift_With_Local_Surface_Geometry_for_Point_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_LSG-CPD_Coherent_Point_Drift_With_Local_Surface_Geometry_for_Point_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Liu_LSG-CPD_Coherent_Point_ICCV_2021_supplemental.pdf)]
8. Lu_HRegNet_A_Hierarchical_Network_for_Large-Scale_Outdoor_LiDAR_Point_Cloud_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lu_HRegNet_A_Hierarchical_Network_for_Large-Scale_Outdoor_LiDAR_Point_Cloud_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lu_HRegNet_A_Hierarchical_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2107.11992)] 
9. Min_Distinctiveness_Oriented_Positional_Equilibrium_for_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Min_Distinctiveness_Oriented_Positional_Equilibrium_for_Point_Cloud_Registration_ICCV_2021_paper.pdf)]
10. Nie_Differentiable_Convolution_Search_for_Point_Cloud_Processing_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Nie_Differentiable_Convolution_Search_for_Point_Cloud_Processing_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Nie_Differentiable_Convolution_Search_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.12856)]
11. Wu_Feature_Interactive_Representation_for_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Feature_Interactive_Representation_for_Point_Cloud_Registration_ICCV_2021_paper.pdf)]
12. Xiang_Walk_in_the_Cloud_Learning_Curves_for_Point_Clouds_Shape_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xiang_Walk_in_the_Cloud_Learning_Curves_for_Point_Clouds_Shape_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2105.01288)]
13. Xu_OMNet_Learning_Overlapping_Mask_for_Partial-to-Partial_Point_Cloud_Registration_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_OMNet_Learning_Overlapping_Mask_for_Partial-to-Partial_Point_Cloud_Registration_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_OMNet_Learning_Overlapping_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.00937)]
14. Yang_Dynamical_Pose_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Dynamical_Pose_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Yang_Dynamical_Pose_Estimation_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.06182)]

#### Calibration:

1. Lochman_BabelCalib_A_Universal_Approach_to_Calibrating_Central_Cameras_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lochman_BabelCalib_A_Universal_Approach_to_Calibrating_Central_Cameras_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lochman_BabelCalib_A_Universal_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.09704)] 

#### Dataset:

1. Jafarzadeh_CrowdDriven_A_New_Challenging_Dataset_for_Outdoor_Visual_Localization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jafarzadeh_CrowdDriven_A_New_Challenging_Dataset_for_Outdoor_Visual_Localization_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jafarzadeh_CrowdDriven_A_New_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.04527)]

#### Depth:

1. Bae_Estimating_and_Exploiting_the_Aleatoric_Uncertainty_in_Surface_Normal_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Bae_Estimating_and_Exploiting_the_Aleatoric_Uncertainty_in_Surface_Normal_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Bae_Estimating_and_Exploiting_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.09881)]
2. Chen_Revealing_the_Reciprocal_Relations_Between_Self-Supervised_Stereo_and_Monocular_Depth_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Revealing_the_Reciprocal_Relations_Between_Self-Supervised_Stereo_and_Monocular_Depth_ICCV_2021_paper.pdf)] 
3. Choi_Adaptive_Confidence_Thresholding_for_Monocular_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Choi_Adaptive_Confidence_Thresholding_for_Monocular_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Choi_Adaptive_Confidence_Thresholding_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2009.12840)]
4. Huang_Fast_Light-Field_Disparity_Estimation_With_Multi-Disparity-Scale_Cost_Aggregation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Fast_Light-Field_Disparity_Estimation_With_Multi-Disparity-Scale_Cost_Aggregation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Huang_Fast_Light-Field_Disparity_ICCV_2021_supplemental.pdf)]
5. Huynh_Boosting_Monocular_Depth_Estimation_With_Lightweight_3D_Point_Fusion_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Huynh_Boosting_Monocular_Depth_Estimation_With_Lightweight_3D_Point_Fusion_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Huynh_Boosting_Monocular_Depth_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2012.10296)]
6. Ji_MonoIndoor_Towards_Good_Practice_of_Self-Supervised_Monocular_Depth_Estimation_for_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ji_MonoIndoor_Towards_Good_Practice_of_Self-Supervised_Monocular_Depth_Estimation_for_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ji_MonoIndoor_Towards_Good_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2107.12429)]
7. Johari_DepthInSpace_Exploitation_and_Fusion_of_Multiple_Video_Frames_for_Structured-Light_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Johari_DepthInSpace_Exploitation_and_Fusion_of_Multiple_Video_Frames_for_Structured-Light_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Johari_DepthInSpace_Exploitation_and_ICCV_2021_supplemental.pdf)]
8. Jung_Fine-Grained_Semantics-Aware_Representation_Enhancement_for_Self-Supervised_Monocular_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jung_Fine-Grained_Semantics-Aware_Representation_Enhancement_for_Self-Supervised_Monocular_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jung_Fine-Grained_Semantics-Aware_Representation_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08829)]
9. Kang_Learning_Efficient_Photometric_Feature_Transform_for_Multi-View_Stereo_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Kang_Learning_Efficient_Photometric_Feature_Transform_for_Multi-View_Stereo_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2103.14794)]
10. Kim_Just_a_Few_Points_Are_All_You_Need_for_Multi-View_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Just_a_Few_Points_Are_All_You_Need_for_Multi-View_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kim_Just_a_Few_ICCV_2021_supplemental.pdf)]
11. Lee_Attentive_and_Contrastive_Learning_for_Joint_Depth_and_Motion_Field_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_Attentive_and_Contrastive_Learning_for_Joint_Depth_and_Motion_Field_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lee_Attentive_and_Contrastive_ICCV_2021_supplemental.pdf)]
12. Lee_PatchMatch-RL_Deep_MVS_With_Pixelwise_Depth_Normal_and_Visibility_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_PatchMatch-RL_Deep_MVS_With_Pixelwise_Depth_Normal_and_Visibility_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lee_PatchMatch-RL_Deep_MVS_ICCV_2021_supplemental.pdf)]
13. Li_Revisiting_Stereo_Depth_Estimation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Revisiting_Stereo_Depth_Estimation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Li_Revisiting_Stereo_Depth_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2011.02910)] 
14. Li_StructDepth_Leveraging_the_Structural_Regularities_for_Self-Supervised_Indoor_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_StructDepth_Leveraging_the_Structural_Regularities_for_Self-Supervised_Indoor_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Li_StructDepth_Leveraging_the_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08574)]
15. Logothetis_PX-NET_Simple_and_Efficient_Pixel-Wise_Training_of_Photometric_Stereo_Networks_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Logothetis_PX-NET_Simple_and_Efficient_Pixel-Wise_Training_of_Photometric_Stereo_Networks_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Logothetis_PX-NET_Simple_and_ICCV_2021_supplemental.pdf)]
16. Long_Adaptive_Surface_Normal_Constraint_for_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Long_Adaptive_Surface_Normal_Constraint_for_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Long_Adaptive_Surface_Normal_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.15483)]
17. Ma_EPP-MVSNet_Epipolar-Assembling_Based_Depth_Prediction_for_Multi-View_Stereo_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ma_EPP-MVSNet_Epipolar-Assembling_Based_Depth_Prediction_for_Multi-View_Stereo_ICCV_2021_paper.pdf)]
18. Mostafavi_Event-Intensity_Stereo_Estimating_Depth_by_the_Best_of_Both_Worlds_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Mostafavi_Event-Intensity_Stereo_Estimating_Depth_by_the_Best_of_Both_Worlds_ICCV_2021_paper.pdf)]
19. Peng_Excavating_the_Potential_Capacity_of_Self-Supervised_Monocular_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Peng_Excavating_the_Potential_Capacity_of_Self-Supervised_Monocular_Depth_Estimation_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2109.12484)]
20. Qu_Bayesian_Deep_Basis_Fitting_for_Depth_Completion_With_Uncertainty_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Qu_Bayesian_Deep_Basis_Fitting_for_Depth_Completion_With_Uncertainty_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Qu_Bayesian_Deep_Basis_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.15254)]
21. Tilmon_SaccadeCam_Adaptive_Visual_Attention_for_Monocular_Depth_Sensing_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Tilmon_SaccadeCam_Adaptive_Visual_Attention_for_Monocular_Depth_Sensing_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Tilmon_SaccadeCam_Adaptive_Visual_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.12981)]
22. Wang_Can_Scale-Consistent_Monocular_Depth_Be_Learned_in_a_Self-Supervised_Scale-Invariant_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Can_Scale-Consistent_Monocular_Depth_Be_Learned_in_a_Self-Supervised_Scale-Invariant_ICCV_2021_paper.pdf)]
23. Wang_Domain_Adaptive_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Domain_Adaptive_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wang_Domain_Adaptive_Semantic_ICCV_2021_supplemental.pdf)]
24. Wang_Regularizing_Nighttime_Weirdness_Efficient_Self-Supervised_Monocular_Depth_Estimation_in_the_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Regularizing_Nighttime_Weirdness_Efficient_Self-Supervised_Monocular_Depth_Estimation_in_the_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wang_Regularizing_Nighttime_Weirdness_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.03830)] 
25. Wei_NerfingMVS_Guided_Optimization_of_Neural_Radiance_Fields_for_Indoor_Multi-View_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wei_NerfingMVS_Guided_Optimization_of_Neural_Radiance_Fields_for_Indoor_Multi-View_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wei_NerfingMVS_Guided_Optimization_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2109.01129)] 
26. Wong_Unsupervised_Depth_Completion_With_Calibrated_Backprojection_Layers_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wong_Unsupervised_Depth_Completion_With_Calibrated_Backprojection_Layers_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wong_Unsupervised_Depth_Completion_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.10531)]
27. Workman_Augmenting_Depth_Estimation_With_Geospatial_Context_ICCV_2021_paper [[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Workman_Augmenting_Depth_Estimation_With_Geospatial_Context_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Workman_Augmenting_Depth_Estimation_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2109.09879)] 
28. Xu_Digging_Into_Uncertainty_in_Self-Supervised_Multi-View_Stereo_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_Digging_Into_Uncertainty_in_Self-Supervised_Multi-View_Stereo_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_Digging_Into_Uncertainty_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.12966)]
29. You_Towards_Interpretable_Deep_Networks_for_Monocular_Depth_Estimation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/You_Towards_Interpretable_Deep_Networks_for_Monocular_Depth_Estimation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/You_Towards_Interpretable_Deep_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.05312)] 
30. Zhao_A_Confidence-Based_Iterative_Solver_of_Depths_and_Surface_Normals_for_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_A_Confidence-Based_Iterative_Solver_of_Depths_and_Surface_Normals_for_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhao_A_Confidence-Based_Iterative_ICCV_2021_supplemental.pdf)] 
31. Zhou_R-MSFM_Recurrent_Multi-Scale_Feature_Modulation_for_Monocular_Depth_Estimating_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_R-MSFM_Recurrent_Multi-Scale_Feature_Modulation_for_Monocular_Depth_Estimating_ICCV_2021_paper.pdf)]
32. [Self-Supervised Monocular Depth Estimation for All Day Images Using Domain Separation](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Self-Supervised_Monocular_Depth_Estimation_for_All_Day_Images_Using_Domain_ICCV_2021_paper.html) [[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Self-Supervised_Monocular_Depth_Estimation_for_All_Day_Images_Using_Domain_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2108.07628)]
33. [DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes](https://openaccess.thecvf.com/content/ICCV2021/html/Jung_DnD_Dense_Depth_Estimation_in_Crowded_Dynamic_Indoor_Scenes_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jung_DnD_Dense_Depth_Estimation_in_Crowded_Dynamic_Indoor_Scenes_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jung_DnD_Dense_Depth_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.05615)]

#### Reconstruction:

1. Bednarik_Temporally-Coherent_Surface_Reconstruction_via_Metric-Consistent_Atlases_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Bednarik_Temporally-Coherent_Surface_Reconstruction_via_Metric-Consistent_Atlases_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Bednarik_Temporally-Coherent_Surface_Reconstruction_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2104.06950)]
2. Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Unsupervised_Learning_of_Fine_Structure_Generation_for_3D_Point_Clouds_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Chen_Unsupervised_Learning_of_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.03746)]
3. Choe_VolumeFusion_Deep_Depth_Fusion_for_3D_Scene_Reconstruction_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Choe_VolumeFusion_Deep_Depth_Fusion_for_3D_Scene_Reconstruction_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Choe_VolumeFusion_Deep_Depth_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08623)] 
4. Dabral_Gravity-Aware_Monocular_3D_Human-Object_Reconstruction_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Dabral_Gravity-Aware_Monocular_3D_Human-Object_Reconstruction_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Dabral_Gravity-Aware_Monocular_3D_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08844)]
5. Hamdi_MVTN_Multi-View_Transformation_Network_for_3D_Shape_Recognition_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Hamdi_MVTN_Multi-View_Transformation_Network_for_3D_Shape_Recognition_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Hamdi_MVTN_Multi-View_Transformation_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2011.13244)]
6. Jiang_Focal_Frequency_Loss_for_Image_Reconstruction_and_Synthesis_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_Focal_Frequency_Loss_for_Image_Reconstruction_and_Synthesis_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jiang_Focal_Frequency_Loss_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2012.12821)] 
7. Li_3D_Building_Reconstruction_From_Monocular_Remote_Sensing_Images_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_3D_Building_Reconstruction_From_Monocular_Remote_Sensing_Images_ICCV_2021_paper.pdf)]
8. Poliarnyi_Out-of-Core_Surface_Reconstruction_via_Global_TGV_Minimization_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Poliarnyi_Out-of-Core_Surface_Reconstruction_via_Global_TGV_Minimization_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Poliarnyi_Out-of-Core_Surface_Reconstruction_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2107.14790)] 
9. Reed_Dynamic_CT_Reconstruction_From_Limited_Views_With_Implicit_Neural_Representations_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Reed_Dynamic_CT_Reconstruction_From_Limited_Views_With_Implicit_Neural_Representations_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Reed_Dynamic_CT_Reconstruction_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2104.11745)]
10. Shi_Geometric_Granularity_Aware_Pixel-To-Mesh_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Shi_Geometric_Granularity_Aware_Pixel-To-Mesh_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Shi_Geometric_Granularity_Aware_ICCV_2021_supplemental.zip)]
11. Song_Vis2Mesh_Efficient_Mesh_Reconstruction_From_Unstructured_Point_Clouds_of_Large_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Song_Vis2Mesh_Efficient_Mesh_Reconstruction_From_Unstructured_Point_Clouds_of_Large_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Song_Vis2Mesh_Efficient_Mesh_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08378)]
12. Tan_PlaneTR_Structure-Guided_Transformers_for_3D_Plane_Recovery_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Tan_PlaneTR_Structure-Guided_Transformers_for_3D_Plane_Recovery_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Tan_PlaneTR_Structure-Guided_Transformers_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2107.13108)]
13. Wang_Multi-View_3D_Reconstruction_With_Transformers_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Multi-View_3D_Reconstruction_With_Transformers_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wang_Multi-View_3D_Reconstruction_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2103.12957)] 
14. Wei_Deep_Hybrid_Self-Prior_for_Full_3D_Mesh_Generation_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wei_Deep_Hybrid_Self-Prior_for_Full_3D_Mesh_Generation_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wei_Deep_Hybrid_Self-Prior_ICCV_2021_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2108.08017)] 
15. Xiong_In-the-Wild_Single_Camera_3D_Reconstruction_Through_Moving_Water_Surfaces_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Xiong_In-the-Wild_Single_Camera_3D_Reconstruction_Through_Moving_Water_Surfaces_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xiong_In-the-Wild_Single_Camera_ICCV_2021_supplemental.pdf)]
16. Zhang_Interacting_Two-Hand_3D_Pose_and_Shape_Reconstruction_From_Single_Color_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Interacting_Two-Hand_3D_Pose_and_Shape_Reconstruction_From_Single_Color_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_Interacting_Two-Hand_3D_ICCV_2021_supplemental.pdf)]
17. Zhang_Learning_Signed_Distance_Field_for_Multi-View_Surface_Reconstruction_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Learning_Signed_Distance_Field_for_Multi-View_Surface_Reconstruction_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_Learning_Signed_Distance_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2108.09964)] 
18. Zhu_Semantic-Embedded_Unsupervised_Spectral_Reconstruction_From_Single_RGB_Images_in_the_ICCV_2021_paper[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Semantic-Embedded_Unsupervised_Spectral_Reconstruction_From_Single_RGB_Images_in_the_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhu_Semantic-Embedded_Unsupervised_Spectral_ICCV_2021_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2108.06659)]
19. [Planar Surface Reconstruction From Sparse Views](https://openaccess.thecvf.com/content/ICCV2021/html/Jin_Planar_Surface_Reconstruction_From_Sparse_Views_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Jin_Planar_Surface_Reconstruction_From_Sparse_Views_ICCV_2021_paper.pdf)] [[arXiv](http://arxiv.org/abs/2103.14644)]
20. [Adaptive Surface Reconstruction With Multiscale Convolutional Kernels](https://openaccess.thecvf.com/content/ICCV2021/html/Ummenhofer_Adaptive_Surface_Reconstruction_With_Multiscale_Convolutional_Kernels_ICCV_2021_paper.html)[[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Ummenhofer_Adaptive_Surface_Reconstruction_With_Multiscale_Convolutional_Kernels_ICCV_2021_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ummenhofer_Adaptive_Surface_Reconstruction_ICCV_2021_supplemental.zip)]
